# Use YARN as the cluster manager
spark.master                     yarn

# Deploy driver inside the cluster (change to 'client' if you want local driver)
spark.submit.deployMode          cluster

# Set your Hadoop resource manager address
spark.hadoop.yarn.resourcemanager.address     <your-resourcemanager-host>:8032

# HDFS default filesystem
spark.hadoop.fs.defaultFS         hdfs://<your-namenode-host>:8020

# Memory and cores for driver and executors
spark.driver.memory              1g
spark.executor.memory            2g
spark.executor.cores             2

# Number of executors (adjust based on cluster capacity)
spark.executor.instances         3

# Application name
spark.app.name                   MySparkApp

# Logging level
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://<your-namenode-host>:8020/spark-logs

# Shuffle service settings for dynamic allocation
spark.shuffle.service.enabled    true
spark.dynamicAllocation.enabled  true
spark.dynamicAllocation.minExecutors 1
spark.dynamicAllocation.maxExecutors 5

# Enable yarn client node to fetch logs from ResourceManager
spark.yarn.am.waitTime           1000000

# Serializer settings
spark.serializer                org.apache.spark.serializer.KryoSerializer
